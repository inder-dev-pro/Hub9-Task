{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce2d28e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-22T12:56:56.456325Z",
     "iopub.status.busy": "2025-05-22T12:56:56.455991Z",
     "iopub.status.idle": "2025-05-22T12:56:57.672138Z",
     "shell.execute_reply": "2025-05-22T12:56:57.670877Z"
    },
    "papermill": {
     "duration": 1.226719,
     "end_time": "2025-05-22T12:56:57.674303",
     "exception": false,
     "start_time": "2025-05-22T12:56:56.447584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc94db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T12:56:57.686904Z",
     "iopub.status.busy": "2025-05-22T12:56:57.686336Z",
     "iopub.status.idle": "2025-05-22T12:57:16.253760Z",
     "shell.execute_reply": "2025-05-22T12:57:16.252339Z"
    },
    "papermill": {
     "duration": 18.575699,
     "end_time": "2025-05-22T12:57:16.255760",
     "exception": false,
     "start_time": "2025-05-22T12:56:57.680061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96afa898",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T12:57:16.267335Z",
     "iopub.status.busy": "2025-05-22T12:57:16.266692Z",
     "iopub.status.idle": "2025-05-22T12:57:25.238330Z",
     "shell.execute_reply": "2025-05-22T12:57:25.236964Z"
    },
    "papermill": {
     "duration": 8.97975,
     "end_time": "2025-05-22T12:57:25.240317",
     "exception": false,
     "start_time": "2025-05-22T12:57:16.260567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_data = pd.read_csv('/kaggle/input/heartbeat/mitbih_train.csv', header=None)\n",
    "test_data = pd.read_csv('/kaggle/input/heartbeat/mitbih_test.csv', header=None)\n",
    "abnormal_data = pd.read_csv('/kaggle/input/heartbeat/ptbdb_abnormal.csv', header=None)\n",
    "normal_data = pd.read_csv('/kaggle/input/heartbeat/ptbdb_normal.csv', header=None)\n",
    "\n",
    "# Combine the abnormal and normal data\n",
    "normal_data['label'] = 0\n",
    "abnormal_data['label'] = 1\n",
    "\n",
    "# Combine all datasets\n",
    "combined_data = pd.concat([train_data, test_data, normal_data, abnormal_data], axis=0)\n",
    "\n",
    "# Split features and labels\n",
    "X = combined_data.iloc[:, :-1].values\n",
    "y = combined_data.iloc[:, -1].values\n",
    "\n",
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape for CNN (if data is time-series, reshape accordingly)\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563df017",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T12:57:25.252051Z",
     "iopub.status.busy": "2025-05-22T12:57:25.251655Z",
     "iopub.status.idle": "2025-05-22T12:57:25.265677Z",
     "shell.execute_reply": "2025-05-22T12:57:25.264320Z"
    },
    "papermill": {
     "duration": 0.022052,
     "end_time": "2025-05-22T12:57:25.267405",
     "exception": false,
     "start_time": "2025-05-22T12:57:25.245353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "print(combined_data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1590b64b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T12:57:25.277225Z",
     "iopub.status.busy": "2025-05-22T12:57:25.276834Z",
     "iopub.status.idle": "2025-05-22T12:57:28.709779Z",
     "shell.execute_reply": "2025-05-22T12:57:28.708507Z"
    },
    "papermill": {
     "duration": 3.439782,
     "end_time": "2025-05-22T12:57:28.711637",
     "exception": false,
     "start_time": "2025-05-22T12:57:25.271855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "train_data = pd.read_csv('/kaggle/input/heartbeat/mitbih_test.csv', header=None)\n",
    "test_data = pd.read_csv('/kaggle/input/heartbeat/mitbih_train.csv', header=None)\n",
    "abnormal_data = pd.read_csv('/kaggle/input/heartbeat/ptbdb_abnormal.csv', header=None)\n",
    "normal_data = pd.read_csv('/kaggle/input/heartbeat/ptbdb_normal.csv', header=None)\n",
    "\n",
    "# Combine the abnormal and normal data\n",
    "normal_data['label'] = 0\n",
    "abnormal_data['label'] = 1\n",
    "\n",
    "# Combine all datasets\n",
    "combined_data = pd.concat([train_data, test_data, normal_data, abnormal_data], axis=0)\n",
    "\n",
    "# Check and handle missing values\n",
    "print(\"Missing values in labels:\", combined_data['label'].isna().sum())\n",
    "print(\"Missing values in features:\", combined_data.isna().sum().sum())\n",
    "\n",
    "# Drop rows with NaN values in the label column\n",
    "combined_data = combined_data.dropna(subset=['label'])\n",
    "\n",
    "# Check again\n",
    "print(\"Missing values in cleaned labels:\", combined_data['label'].isna().sum())\n",
    "print(\"Missing values in cleaned features:\", combined_data.isna().sum().sum())\n",
    "\n",
    "# Split features and labels\n",
    "X = combined_data.iloc[:, :-1].values\n",
    "y = combined_data.iloc[:, -1].values\n",
    "\n",
    "# Confirm no NaNs in y\n",
    "print(\"NaNs in y:\", np.isnan(y).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cddb46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T12:57:28.721927Z",
     "iopub.status.busy": "2025-05-22T12:57:28.721539Z",
     "iopub.status.idle": "2025-05-22T13:02:53.521207Z",
     "shell.execute_reply": "2025-05-22T13:02:53.519036Z"
    },
    "papermill": {
     "duration": 324.806856,
     "end_time": "2025-05-22T13:02:53.523214",
     "exception": false,
     "start_time": "2025-05-22T12:57:28.716358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load datasets\n",
    "train_data = pd.read_csv('/kaggle/input/heartbeat/mitbih_test.csv', header=None)\n",
    "test_data = pd.read_csv('/kaggle/input/heartbeat/mitbih_train.csv', header=None)\n",
    "abnormal_data = pd.read_csv('/kaggle/input/heartbeat/ptbdb_abnormal.csv', header=None)\n",
    "normal_data = pd.read_csv('/kaggle/input/heartbeat/ptbdb_normal.csv', header=None)\n",
    "\n",
    "\n",
    "# Combine the abnormal and normal data\n",
    "normal_data['label'] = 0\n",
    "abnormal_data['label'] = 1\n",
    "\n",
    "# Combine all datasets\n",
    "combined_data = pd.concat([train_data, test_data, normal_data, abnormal_data], axis=0)\n",
    "\n",
    "# Check and handle missing values\n",
    "print(\"Missing values in labels:\", combined_data['label'].isna().sum())\n",
    "print(\"Missing values in features:\", combined_data.isna().sum().sum())\n",
    "\n",
    "# Drop rows with NaN values in the label column\n",
    "combined_data = combined_data.dropna(subset=['label'])\n",
    "\n",
    "# Verify again after cleaning\n",
    "print(\"Missing values in cleaned labels:\", combined_data['label'].isna().sum())\n",
    "print(\"Missing values in cleaned features:\", combined_data.isna().sum().sum())\n",
    "\n",
    "# Split features and labels\n",
    "X = combined_data.iloc[:, :-1].values\n",
    "y = combined_data.iloc[:, -1].values\n",
    "\n",
    "# Confirm no NaNs in y\n",
    "print(\"NaNs in y:\", np.isnan(y).sum())\n",
    "\n",
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Resample data to handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Reshape for CNN\n",
    "X_resampled = X_resampled.reshape((X_resampled.shape[0], X_resampled.shape[1], 1))\n",
    "\n",
    "# Split resampled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_resampled), y=y_resampled)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "#Building the model\n",
    "model = Sequential([\n",
    "    Conv1D(120, 5, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    MaxPooling1D(2),\n",
    "    Dropout(0.45),\n",
    "    Conv1D(240, 5, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Dropout(0.45),\n",
    "    Flatten(),\n",
    "    Dense(240, activation='relu'),\n",
    "    Dropout(0.45),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model with class weights\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.2, class_weight=class_weight_dict)\n",
    "\n",
    "# Evaluate model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21f1872",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:02:53.897169Z",
     "iopub.status.busy": "2025-05-22T13:02:53.896733Z",
     "iopub.status.idle": "2025-05-22T13:02:53.908561Z",
     "shell.execute_reply": "2025-05-22T13:02:53.907330Z"
    },
    "papermill": {
     "duration": 0.200651,
     "end_time": "2025-05-22T13:02:53.910394",
     "exception": false,
     "start_time": "2025-05-22T13:02:53.709743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract training and validation accuracy and loss from the history object\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Print training and validation accuracy and loss\n",
    "print(\"\\nTraining and Validation Accuracy:\")\n",
    "for epoch in range(len(train_acc)):\n",
    "    print(f\"Epoch {epoch + 1}: Training Accuracy = {train_acc[epoch]:.4f}, Validation Accuracy = {val_acc[epoch]:.4f}\")\n",
    "\n",
    "print(\"\\nTraining and Validation Loss:\")\n",
    "for epoch in range(len(train_loss)):\n",
    "    print(f\"Epoch {epoch + 1}: Training Loss = {train_loss[epoch]:.4f}, Validation Loss = {val_loss[epoch]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2295f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:02:54.339372Z",
     "iopub.status.busy": "2025-05-22T13:02:54.338948Z",
     "iopub.status.idle": "2025-05-22T13:02:56.963081Z",
     "shell.execute_reply": "2025-05-22T13:02:56.961878Z"
    },
    "papermill": {
     "duration": 2.812834,
     "end_time": "2025-05-22T13:02:56.964947",
     "exception": false,
     "start_time": "2025-05-22T13:02:54.152113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Abnormal'], yticklabels=['Normal', 'Abnormal'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4ba02d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:02:57.336081Z",
     "iopub.status.busy": "2025-05-22T13:02:57.335489Z",
     "iopub.status.idle": "2025-05-22T13:02:58.015473Z",
     "shell.execute_reply": "2025-05-22T13:02:58.014409Z"
    },
    "papermill": {
     "duration": 0.866629,
     "end_time": "2025-05-22T13:02:58.016919",
     "exception": false,
     "start_time": "2025-05-22T13:02:57.150290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract training and validation accuracy and loss from the history object\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f07b70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:02:58.398343Z",
     "iopub.status.busy": "2025-05-22T13:02:58.398010Z",
     "iopub.status.idle": "2025-05-22T13:02:58.588856Z",
     "shell.execute_reply": "2025-05-22T13:02:58.587392Z"
    },
    "papermill": {
     "duration": 0.38109,
     "end_time": "2025-05-22T13:02:58.590671",
     "exception": false,
     "start_time": "2025-05-22T13:02:58.209581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import spectrogram\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a054ef4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:02:59.044393Z",
     "iopub.status.busy": "2025-05-22T13:02:59.043424Z",
     "iopub.status.idle": "2025-05-22T13:03:01.831897Z",
     "shell.execute_reply": "2025-05-22T13:03:01.830010Z"
    },
    "papermill": {
     "duration": 2.992417,
     "end_time": "2025-05-22T13:03:01.834172",
     "exception": false,
     "start_time": "2025-05-22T13:02:58.841755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/kaggle/input/heartbeat/mitbih_train.csv', header=None)\n",
    "data_test = pd.read_csv('/kaggle/input/heartbeat/mitbih_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216bc504",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:03:02.222716Z",
     "iopub.status.busy": "2025-05-22T13:03:02.222358Z",
     "iopub.status.idle": "2025-05-22T13:03:02.227128Z",
     "shell.execute_reply": "2025-05-22T13:03:02.225915Z"
    },
    "papermill": {
     "duration": 0.195319,
     "end_time": "2025-05-22T13:03:02.228864",
     "exception": false,
     "start_time": "2025-05-22T13:03:02.033545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89409d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:03:02.668922Z",
     "iopub.status.busy": "2025-05-22T13:03:02.668563Z",
     "iopub.status.idle": "2025-05-22T13:03:02.673213Z",
     "shell.execute_reply": "2025-05-22T13:03:02.671957Z"
    },
    "papermill": {
     "duration": 0.260653,
     "end_time": "2025-05-22T13:03:02.674823",
     "exception": false,
     "start_time": "2025-05-22T13:03:02.414170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = data_test.iloc[:, :-1].values\n",
    "y_test = data_test.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56142494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:03:03.046596Z",
     "iopub.status.busy": "2025-05-22T13:03:03.046262Z",
     "iopub.status.idle": "2025-05-22T13:03:03.226035Z",
     "shell.execute_reply": "2025-05-22T13:03:03.225026Z"
    },
    "papermill": {
     "duration": 0.367939,
     "end_time": "2025-05-22T13:03:03.227539",
     "exception": false,
     "start_time": "2025-05-22T13:03:02.859600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3328afb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:03:03.600303Z",
     "iopub.status.busy": "2025-05-22T13:03:03.600013Z",
     "iopub.status.idle": "2025-05-22T13:03:03.604798Z",
     "shell.execute_reply": "2025-05-22T13:03:03.603176Z"
    },
    "papermill": {
     "duration": 0.193559,
     "end_time": "2025-05-22T13:03:03.606729",
     "exception": false,
     "start_time": "2025-05-22T13:03:03.413170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert signals to 2D spectrogram images\n",
    "def signal_to_spectrogram(signal):\n",
    "    f, t, Sxx = spectrogram(signal, fs=100, nperseg=64, noverlap=32)\n",
    "    return Sxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d267241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:03:03.970139Z",
     "iopub.status.busy": "2025-05-22T13:03:03.969721Z",
     "iopub.status.idle": "2025-05-22T13:03:22.953282Z",
     "shell.execute_reply": "2025-05-22T13:03:22.951770Z"
    },
    "papermill": {
     "duration": 19.168952,
     "end_time": "2025-05-22T13:03:22.955049",
     "exception": false,
     "start_time": "2025-05-22T13:03:03.786097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the entire dataset to spectrograms\n",
    "X_spectrograms = np.array([signal_to_spectrogram(signal) for signal in X])\n",
    "X_test_spectrograms = np.array([signal_to_spectrogram(signal) for signal in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db316d17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:03:23.392357Z",
     "iopub.status.busy": "2025-05-22T13:03:23.391991Z",
     "iopub.status.idle": "2025-05-22T13:03:23.396984Z",
     "shell.execute_reply": "2025-05-22T13:03:23.395671Z"
    },
    "papermill": {
     "duration": 0.193146,
     "end_time": "2025-05-22T13:03:23.398990",
     "exception": false,
     "start_time": "2025-05-22T13:03:23.205844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reshape for Conv2D input\n",
    "X_spectrograms = X_spectrograms[..., np.newaxis]  # Add channel dimension\n",
    "X_test_spectrograms = X_test_spectrograms[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc7af2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:03:23.767280Z",
     "iopub.status.busy": "2025-05-22T13:03:23.766932Z",
     "iopub.status.idle": "2025-05-22T13:03:23.772597Z",
     "shell.execute_reply": "2025-05-22T13:03:23.771662Z"
    },
    "papermill": {
     "duration": 0.192547,
     "end_time": "2025-05-22T13:03:23.773793",
     "exception": false,
     "start_time": "2025-05-22T13:03:23.581246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert labels to categorical\n",
    "y_categorical = to_categorical(y)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26be340",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:03:24.142980Z",
     "iopub.status.busy": "2025-05-22T13:03:24.142580Z",
     "iopub.status.idle": "2025-05-22T13:03:24.180071Z",
     "shell.execute_reply": "2025-05-22T13:03:24.178495Z"
    },
    "papermill": {
     "duration": 0.225402,
     "end_time": "2025-05-22T13:03:24.182041",
     "exception": false,
     "start_time": "2025-05-22T13:03:23.956639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the training data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_spectrograms, y_categorical, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca2428b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:03:24.552352Z",
     "iopub.status.busy": "2025-05-22T13:03:24.552017Z",
     "iopub.status.idle": "2025-05-22T13:03:24.601331Z",
     "shell.execute_reply": "2025-05-22T13:03:24.599992Z"
    },
    "papermill": {
     "duration": 0.238039,
     "end_time": "2025-05-22T13:03:24.602791",
     "exception": false,
     "start_time": "2025-05-22T13:03:24.364752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build 2D CNN model with 'same' padding\n",
    "model_2d_cnn = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=X_train.shape[1:]),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(y_categorical.shape[1], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4be70c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:03:25.037001Z",
     "iopub.status.busy": "2025-05-22T13:03:25.036642Z",
     "iopub.status.idle": "2025-05-22T13:03:25.046661Z",
     "shell.execute_reply": "2025-05-22T13:03:25.045125Z"
    },
    "papermill": {
     "duration": 0.198574,
     "end_time": "2025-05-22T13:03:25.048787",
     "exception": false,
     "start_time": "2025-05-22T13:03:24.850213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_2d_cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c587beb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:03:25.421211Z",
     "iopub.status.busy": "2025-05-22T13:03:25.420865Z",
     "iopub.status.idle": "2025-05-22T13:09:26.235703Z",
     "shell.execute_reply": "2025-05-22T13:09:26.233970Z"
    },
    "papermill": {
     "duration": 361.002893,
     "end_time": "2025-05-22T13:09:26.237527",
     "exception": false,
     "start_time": "2025-05-22T13:03:25.234634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model_2d_cnn.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a94319a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:09:27.181982Z",
     "iopub.status.busy": "2025-05-22T13:09:27.181603Z",
     "iopub.status.idle": "2025-05-22T13:09:29.571873Z",
     "shell.execute_reply": "2025-05-22T13:09:29.570615Z"
    },
    "papermill": {
     "duration": 2.899343,
     "end_time": "2025-05-22T13:09:29.573788",
     "exception": false,
     "start_time": "2025-05-22T13:09:26.674445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model_2d_cnn.evaluate(X_test_spectrograms, y_test_categorical)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5be619",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:09:30.455391Z",
     "iopub.status.busy": "2025-05-22T13:09:30.455072Z",
     "iopub.status.idle": "2025-05-22T13:09:30.639116Z",
     "shell.execute_reply": "2025-05-22T13:09:30.637831Z"
    },
    "papermill": {
     "duration": 0.628632,
     "end_time": "2025-05-22T13:09:30.640665",
     "exception": false,
     "start_time": "2025-05-22T13:09:30.012033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee06bf6",
   "metadata": {
    "papermill": {
     "duration": 0.429643,
     "end_time": "2025-05-22T13:09:31.561590",
     "exception": false,
     "start_time": "2025-05-22T13:09:31.131947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Stopping early using TensorFlow EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd00b3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T13:09:32.503856Z",
     "iopub.status.busy": "2025-05-22T13:09:32.503535Z",
     "iopub.status.idle": "2025-05-22T13:17:46.185061Z",
     "shell.execute_reply": "2025-05-22T13:17:46.183323Z"
    },
    "papermill": {
     "duration": 494.126653,
     "end_time": "2025-05-22T13:17:46.186742",
     "exception": false,
     "start_time": "2025-05-22T13:09:32.060089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',  # Monitor validation accuracy\n",
    "                               patience=5,  # Stop training if no improvement after 5 epochs\n",
    "                               restore_best_weights=True)  # Restore the model weights from the epoch with the best validation accuracy\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model_2d_cnn.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,  # Set a higher number of epochs, as early stopping will stop training once it doesn't improve\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping]  # Add the early stopping callback\n",
    ")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model_2d_cnn.evaluate(X_test_spectrograms, y_test_categorical)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 638842,
     "sourceId": 1134513,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1256.568398,
   "end_time": "2025-05-22T13:17:49.585616",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-22T12:56:53.017218",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
